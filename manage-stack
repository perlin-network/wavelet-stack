#! /usr/bin/env bash

# Check for basic commands which are required before this script
# can be useful.
for checkCommand in docker-machine docker jq curl; do
	if [ ! -x "$(command -v "${checkCommand}")" ]; then
		echo "\"${checkCommand}\" is required, but missing" >&2

		exit 1
	fi
done

stackName=''
swarmName=''

function stackRunning() {
	docker stack ps "${stackName}" >/dev/null 2>/dev/null
}

function machinesInSwarm() {
	docker node ls --format '{{.Hostname}}'
}

# Determine if any volumes for the current stack exist on any
# of the nodes in the swarm
function volumesExist() {
	local nodeName
	local retval

	retval='1'
	for nodeName in $(machinesInSwarm); do
		(
			if [ -n "${DOCKER_MACHINE_NAME}" ]; then
				eval "$(docker-machine env "${nodeName}")" || exit 1
			fi

			docker volume list -q | egrep "^${stackName}_(wavelet|sync)_wavelet_db_instance_" >/dev/null
		) && retval='0'
		if [ "${retval}" = '0' ]; then
			break
		fi
	done

	return "${retval}"
}

# Determine if there are any benchmark instances running for
# the current stack
function benchmarkRunning() {
	local replicas

	replicas="$(docker service inspect "${stackName}_benchmark" | jq '.[].Spec.Mode.Replicated.Replicas')"
	if [ -z "${replicas}" ]; then
		replicas='0'
	fi

	if [ "${replicas}" = '0' ]; then
		return 1
	else
		return 0
	fi
}

# Determine, from Docker Swarm, what the Advertised address is
# of the current swarm.
function managerAddress() {
	local managerNode managerAddr

	managerNode="$(docker node ls -q --filter role=manager | sort -R | head -n 1)"
	managerAddr="$(docker node inspect "${managerNode}" | jq -crM '.[0].Status.Addr')"

	echo "${managerAddr}"
}

# For the current stack, look up the exposed port for a given
# internal port
function getExternalPort() {
	local internalPort
	local externalPort

	internalPort="$1"

	if [ -z "${serviceConfigLB_cache}" ]; then
		serviceConfigLB_cache="$(docker service inspect "${stackName}_loadbalancer")"
	fi

	externalPort="$(echo "${serviceConfigLB_cache}" | jq -crM '.[0].Endpoint.Ports[] | select(.TargetPort == '"${internalPort}"') | .PublishedPort')"

	echo "${externalPort}"
}

# In order for the stack to be able to internally map external ports
# to internal ones the stack configuration needs to be accessible to
# the nodes within the stack.  This is done by pushing the Docker
# Stack instance configuration into etcd on the "sync" instance
# whenever it changes.
function pushConfigToEtcd() {
	local managerAddr
	local taskID containerID
	local apiPort rpcPortExternal rpcPortInternal nodeID

	(
		for try in {1..120}; do
			taskID="$(taskIDFromNodeID 'sync')" || taskID=''
			if [ -n "${taskID}" ]; then
				break
			fi

			sleep 0.5
		done

		for try in {1..120}; do
			containerID="$(containerIDFromTaskID "${taskID}")"

			if [ -n "${containerID}" ]; then
				break
			fi
			sleep 0.5
		done

		# Call and discard the result to cache the service config
		getExternalPort -1 >/dev/null 2>/dev/null

		managerAddr="$(managerAddress)"
		for ((rpcPortInternal = 3000; rpcPortInternal <= 4000; rpcPortInternal++)) {
			rpcPortExternal="$(getExternalPort "${rpcPortInternal}")"
			if [ -z "${rpcPortExternal}" ]; then
				break
			fi

			nodeID=$[${rpcPortInternal} - 3000 + 1]

			#echo "${managerAddr}:${rpcPortExternal} -> lb:${rpcPortInternal} -> ${nodeID}/${rpcPortExternal}" >&2
			echo "curl -s -X PUT --data value='${managerAddr}/${rpcPortExternal}/${rpcPortInternal}'  'http://localhost:2379/v2/keys/mapping/${nodeID}' >/dev/null 2>/dev/null </dev/null;"
		} | (
			setDockerMachineForTaskID "${taskID}" </dev/null
			docker exec "${containerID}" sh -c "$(cat << \_EOF_
				while ! curl http://localhost:2379/v2/keys >/dev/null 2>/dev/null; do
					( apk update && apk add curl ) >/dev/null 2>/dev/null
					sleep 0.5
				done
_EOF_
)"
			docker exec -i "${containerID}" sh -
		)
	) || return 1

	return 0
}

# Remove all the volumes for the current stack on a swarm.  This
# returns immediately if "WAVELET_CLEAN_VOLUMES" is not specified
# as exactly "yes"
function cleanVolumes() {
	if [ "$1" = '--force' ]; then
		WAVELET_CLEAN_VOLUMES='yes'
	fi

	if [ "${WAVELET_CLEAN_VOLUMES}" = 'yes' ]; then
		while volumesExist; do
			for nodeName in $(machinesInSwarm); do
				(
					if [ -n "${DOCKER_MACHINE_NAME}" ]; then
						eval "$(docker-machine env "${nodeName}")" || exit 1
					fi

					volumes=( $(docker volume list -q | egrep "^${stackName}_(wavelet|sync)_wavelet_db_instance_") )

					for volume in "${volumes[@]}"; do
						docker volume rm --force "${volume}"
					done
				)
			done

			sleep 0.5
		done
	fi
}

# Stop a stack, repeatedly kicking it while waiting
# for it to reach the desired state (stopped).
# Call cleanVolumes to clean the volumes (which
# will do nothing unless WAVELET_CLEAN_VOLUMES is
# specified as "yes", see above).
function stop() {
	while stackRunning; do
		docker stack rm ${stackName}
		sleep 0.5
	done

	cleanVolumes
}

# Start a stack onto a swarm.  This reads the "docker-compose.yml"
# file and modifies it in order to comply with the current stack
# configuration.  If the stack is already running, it will be
# updated.  This is done by calling "docker deploy".
#
# If WAVELET_REBUILD_ON_START is specified as true then the
# "build-all-nodes" script is run to rebuild all the Docker
# images.
function start() {
	local configFile
	local tmp
	local toDelete

	configFile='./docker-compose.yml'
	toDelete=()

	case "${WAVELET_NO_RPC}" in
		y|Y|yes|true|1) 
			WAVELET_NO_RPC='true'

			tmp="$(mktemp)" || exit 1
			toDelete+=("${tmp}")

			grep -v ' "300[01]-' "${configFile}" | grep -v ' "3000:3000"' > "${tmp}"

			configFile="${tmp}"
			;;
		*)
			tmp="$(mktemp)" || exit 1
			toDelete+=("${tmp}")

			if [ -n "${WAVELET_RPC_PORT}" ]; then
				grep -v ' "3000-' "${configFile}" | sed 's@ "3000:3000"@ "'"${WAVELET_RPC_PORT}"':3000"@' > "${tmp}"
			else
				grep -v ' "3001-' "${configFile}" | grep -v ' "3000:3000"' > "${tmp}"
			fi

			configFile="${tmp}"
			;;
	esac

	if [ -n "${WAVELET_API_PORT}" ]; then
		tmp="$(mktemp)" || exit 1
		toDelete+=("${tmp}")

		sed 's@ "80"@ "'"${WAVELET_API_PORT}"':80"@' "${configFile}" > "${tmp}"

		configFile="${tmp}"
	fi

	if [ -z "${WAVELET_API_HOST}" ]; then
		tmp="$(mktemp)" || exit 1
		toDelete+=("${tmp}")

		grep -v ' "443:443"$' "${configFile}" > "${tmp}"

		configFile="${tmp}"
	else
		if [ -z "${WAVELET_API_ACME_ACCOUNT_KEY}" ]; then
			echo "warning: WAVELET_API_ACME_ACCOUNT_KEY is not specified but WAVELET_API_HOST is, this is probably bad" >&2
		fi
	fi

	case "${WAVELET_REBUILD_ON_START}" in
		y|Y|yes|true|1)
			./build-all-nodes "${stackName}" || return 1
			;;
	esac

	docker stack deploy --prune --with-registry-auth -c "${configFile}" "${stackName}"
	pushConfigToEtcd

	if [ "${#toDelete[@]}" != '0' ]; then
		rm -f "${toDelete[@]}"
	fi
}

# Produce a summary of the status for the current stack on stdout
function status() {
	local running
	local managerAddr
	local apiPort apiHttpsPort apiPortStart rpcPortStart

	echo "${stackName} (on ${swarmName}):"

	if stackRunning; then
		running='true'

		if benchmarkRunning; then
			echo '  - RUNNING BENCHMARKING'
		else
			echo '  - RUNNING'
		fi
	else
		running='false'

		echo '  - NOT RUNNING'
	fi

	if volumesExist; then
		echo '  - VOLUMES'
	else
		echo '  - NO VOLUMES'
	fi

	if [ "${running}" != 'true' ]; then
		return 0
	fi

	managerAddr="$(managerAddress)"
	apiPort="$(getExternalPort 80)"
	apiHttpsPort="$(getExternalPort 443)"
	rpcPortStart="$(getExternalPort 3000)"
	apiPortStart="$(getExternalPort 9000)"

	echo "  - API (main): http://${managerAddr}:${apiPort}/"

	if [ -n "${apiHttpsPort}" ]; then
		echo "  - API (main): https://${managerAddr}:${apiHttpsPort}/"
	fi

	if [ -n "${apiPortStart}" ]; then
		echo "  - API (all): http://${managerAddr}:${apiPortStart}/"
	fi

	if [ -n "${rpcPortStart}" ]; then
		echo "  - RPC: ${managerAddr}:${rpcPortStart}"
	else
		echo "  - RPC: disabled"
	fi

	echo '----'
	if [ "$1" = 'watch' ]; then
		watch --differences=p -n 0.5 docker stack ps --filter 'desired-state=Running' "${stackName}"
	else
		docker stack ps --filter 'desired-state=Running' "${stackName}"
	fi

	return 0
}

# Internal function to set the "docker-machine" environment variables
# to the correct host within a swarm for a specific Docker task ID.
function setDockerMachineForTaskID() {
	local taskID
	local nodeID nodeName

	taskID="$1"

	if [ -n "${DOCKER_MACHINE_NAME}" ]; then
		nodeID="$(docker inspect "${taskID}" | jq -crM '.[0].NodeID')"
		nodeName="$(docker node ls --filter ID="${nodeID}" --format '{{.Hostname}}')"
		eval "$(docker-machine env "${nodeName}")" || return 1
	fi

	return 0
}

# Internal function to look up a Docker containerID from a Docker task ID
function containerIDFromTaskID() {
	local taskID containerID

	taskID="$1"

	containerID="$(docker inspect "${taskID}" | jq -crM '.[0].Status.ContainerStatus.ContainerID')" || return 1
	if [ "${containerID}" = 'null' ]; then
		return 1
	fi

	echo "${containerID}"

	return 0
}

# Utility function to look up the Docker task ID for a given
# Wavelet-Stack "node ID" (such as 1, 2, loadbalancer, etc)
# for the current stack.
function taskIDFromNodeID() {
	local nodeID taskName taskID
	local nodeIndex

	nodeID="$1"
	if [ -z "${nodeID}" ]; then
		echo "ID Required" >&2
		usage >&2
		return 1
	fi

	nodeIndex='1'
	case "${nodeID}" in
		*.*)
			nodeIndex="$(echo "${nodeID}" | cut -f 2 -d .)"
			nodeID="$(echo "${nodeID}" | cut -f 1 -d .)"
			;;
	esac

	case "${nodeID}" in
		benchmark|loadbalancer|sync|wavelet)
			taskName="${stackName}_${nodeID}.${nodeIndex}"
			;;
		*)
			taskName="${stackName}_wavelet.${nodeID}"
			;;
	esac

	taskID="$(docker stack ps -q -f NAME="${taskName}" "${stackName}" | head -n 1)" || return 1
	if [ "${taskID}" = 'null' ]; then
		return 1
	fi

	echo "${taskID}"
}

# CLI function to attach to a node ID for the current stack
function attach() {
	local nodeID taskID containerID

	nodeID="$1"

	if [ -z "${nodeID}" ]; then
		echo "Usage: manage-stack [-s <stackName>] attach <nodeId>" >&2
		return 1
	fi

	taskID="$(taskIDFromNodeID "${nodeID}")" || return 1
	containerID="$(containerIDFromTaskID "${taskID}")" || return 1
	setDockerMachineForTaskID "${taskID}"

	docker attach --sig-proxy=false "${containerID}"
}

# CLI function to create an interactive shell and tty on a particular node ID
# for the current stack, or run a command on that node ID if specified.
function shell() {
	local nodeID taskID containerID
	local allocateTty
	local args

	allocateTty='false'
	if [ "${_internalShellAllocateTTY}" = 'true' ]; then
		allocateTty='true'
	fi

	nodeID="$1"
	shift

	if [ -z "${nodeID}" ]; then
		echo "Usage: manage-stack [-s <stackName>] shell <nodeId> [<args...>]" >&2
		return 1
	fi

	taskID="$(taskIDFromNodeID "${nodeID}")" || return 1
	containerID="$(containerIDFromTaskID "${taskID}")" || return 1
	setDockerMachineForTaskID "${taskID}"

	if [ "$#" = '0' ]; then
		if [ "${nodeID}" = 'sync' ]; then
			set -- sh
		else
			set -- bash
		fi
		allocateTty='true'
	fi

	args=()
	if [ "${allocateTty}" = 'true' ]; then
		args+=(-t)
	fi

	docker exec -i "${args[@]}" "${containerID}" "$@"
}

# CLI function to dump the logs for a given node ID.  This is
# really just a wrapper around "docker service logs"
function logs() {
	local nodeID taskID containerID

	nodeID="$1"
	shift

	if [ -z "${nodeID}" ]; then
		echo "Usage: manage-stack [-s <stackName>] logs <nodeId>" >&2
		return 1
	fi

	taskID="$(taskIDFromNodeID "${nodeID}")" || return 1

	docker service logs "$@" "${taskID}"
}

# CLI function attach a debugger to the wavelet process on a node ID
# on the current stack
function debugWavelet() {
	local nodeID taskID containerID

	nodeID="$1"
	shift

	if [ -z "${nodeID}" ]; then
		echo "Usage: manage-stack [-s <stackName>] debug-wavelet <nodeId>" >&2
		return 1
	fi

	_internalShellAllocateTTY='true'
	shell "${nodeID}" bash -c '/opt/perlin/bin/dlv attach "$(pgrep -x /wavelet)"'
}

# CLI function to print usage information
function usage() {
	echo "Usage: manage-stack [-s <stackName>] {stop|start|update|restart-wavelet|reset|status}"
	echo "       manage-stack [-s <stackName>] benchmark [<count>]"
	echo "       manage-stack [-s <stackName>] nobenchmark"
	echo "       manage-stack [-s <stackName>] {attach|shell|logs|debug-wavelet} <nodeId>"
	echo "       manage-stack [-s <stackName>] {config|edit-config}"
	echo "       manage-stack [-s <stackName>] dump-db <nodeId> <outputFile>"
	echo "       manage-stack [-s <stackName>] cp <src>... <dest>"
	echo "       manage-stack [-s <stackName>] duplicate-stack <newStackName>"
}

# CLI function to update the stack configuration for the current stack
# to scale up/down the number of running benchmark nodes.  By default
# it will scale to 1 benchmark node.  After the benchmark nodes are
# running it will attach to the first benchmark node to print the
# benchmark results interactively
function benchmark() {
	local count

	count="$1"
	if [ -z "${count}" ]; then
		count='1'
	fi

	docker service scale "${stackName}_benchmark=${count}" || return 1
	attach benchmark
}

# CLI function scale the number of benchmark nodes to 0
function nobenchmark() {
	docker service scale "${stackName}_benchmark=0"
}

# CLI function to dump the Wavelet Stack configuration for the current
# stack
function dumpConfig() {
	set | egrep '^(WAVELET_|REGISTRY=)'
}

# CLI function to interactively edit the current stack's Wavelet Stack
# configuration.  It will re-upload it to the first node in the swarm if
# using a remote swarm, otherwise the new configuration will be stored
# in the local configuration file for the stack.
function editConfig() {
	local tmpfile

	tmpfile="$(mktemp)"

	dumpConfig > "${tmpfile}"
	"${VISUAL:-vi}" "${tmpfile}" || rm -f "${tmpfile}"

	if [ -f "${tmpfile}" ]; then
		if [ -n "${DOCKER_MACHINE_NAME}" ]; then
			docker-machine scp "${tmpfile}" "${swarmName}-1:/etc/wavelet-stack/${stackName}" || (
				docker-machine ssh "${swarmName}-1" 'mkdir -p /etc/wavelet-stack'
				docker-machine scp "${tmpfile}" "${swarmName}-1:/etc/wavelet-stack/${stackName}"
			)

			if [ -f "${stackEnvFile}" ]; then
				mv "${stackEnvFile}" "${stackEnvFile}.old" 2>/dev/null
			fi
		else
			mkdir -p "$(dirname "${stackEnvFile}")"
			cp "${tmpfile}" "${stackEnvFile}"
		fi
	fi

	rm -f "${tmpfile}"

	return 0
}

# CLI function to dump the database for a given node ID from the current stack
# into a tarball.
function dumpDB() {
	local nodeID outputFile
	local tmpfile retval

	nodeID="$1"
	outputFile="$2"

	if [ -z "${nodeID}" -o -z "${outputFile}" ]; then
		echo "Usage: manage-stack [-s <stackName>] dump-db <nodeId> <outputFile>" >&2

		return 1
	fi

	(
		shell "${nodeID}" sh -c "$(cat <<\_EOF_
			set -e
			while true; do
				cd /
				rm -rf /db2
				mkdir /db2
				cd /db2
				before="$(cd /db && sha1sum * | sha1sum | awk '{ print $1 }')"
				cp /db/* .
				after="$(cd /db && sha1sum * | sha1sum | awk '{ print $1 }')"
				verify="$(cd /db2 && sha1sum * | sha1sum | awk '{ print $1 }')"
				if [ "${before}" = "${after}" ]; then
					if [ "${verify}" != "${before}" ]; then
						echo "ERROR" >&2
						exit 1
					fi
					break
				fi
				sleep 0.1
			done
			cd /db2
			rm -f /db.tar
			tar -cf /db.tar *
_EOF_
)" || exit 1
	) || return 1

	tmpfile="$(mktemp)"

	(
		shell "${nodeID}" gzip -9c /db.tar
	) > "${tmpfile}"
	retval="$?"

	if [ "${retval}" = '0' ]; then
		cp "${tmpfile}" "${outputFile}"
	fi

	rm -f "${tmpfile}"

	return "${retval}"
}

# Internal function to call "manage-stack" without compounding values
# specified.
function callSelf() {
	(
		unset $(export | grep '^declare -x ' | sed 's@=.*$@@;s@^.* @@')
		eval "${startupEnvironment}"

		./manage-stack "$@"
		exit "$?"
	)
}

# CLI function to duplicate an existing stack into a new one.  This
# copies the configuration and database.  The two stacks do not need
# to be on the same swarm.
function duplicateStack() {
	local destStackName
	local newStackEnvFile
	local tmpDBFile
	local try
	local retval

	destStackName="$1"

	if [ -z "${destStackName}" ]; then
		echo "Usage: manage-stack [-s <stackName>] duplicate-stack <newStackName>" >&2

		return 1
	fi

	if callSelf -s "${destStackName}" status 2>/dev/null | grep '^ *- *RUNNING$' >/dev/null; then
		echo "ERROR: Destination stack (${destStackName}) already exists and is running" >&2

		return 1
	fi

	newStackEnvFile="${configDir}/stacks/${destStackName}"

	if [ -f "${newStackEnvFile}" ]; then
		echo "ERROR: Destination stack (${destStackName}) already has a configuration" >&2

		return 1
	fi

	mkdir -p "$(dirname "${newStackEnvFile}")"
	dumpConfig | egrep -v '^(WAVELET_API_PORT|WAVELET_RPC_PORT)=' > "${newStackEnvFile}"

	retval='0'

	tmpDBFile="$(mktemp)"
	dumpDB 1 "${tmpDBFile}" || retval='1'

	if [ "${retval}" = '0' ]; then
		# Create the stack with exactly 1 node to start, so we can replace the DB
		echo 'WAVELET_NODES=1; # 16441c8f643a0fb87ffb1a5588f32559f62a52de' >> "${newStackEnvFile}"

		callSelf -s "${destStackName}" start || retval='1'

		grep -v '16441c8f643a0fb87ffb1a5588f32559f62a52de' "${newStackEnvFile}" > "${newStackEnvFile}.new"
		cat "${newStackEnvFile}.new" > "${newStackEnvFile}"
		rm -f "${newStackEnvFile}.new"
	fi

	if [ "${retval}" = '0' ]; then
		for try in {1..10} __fail__; do
			if [ "${try}" = '__fail__' ]; then
				return 1
			fi

			callSelf -s "${destStackName}" shell 1 true && break
			sleep 6
		done

		callSelf -s "${destStackName}" cp "${tmpDBFile}" '1:/tmp/db.tar.gz' || retval='1'
	fi

	if [ "${retval}" = '0' ]; then
		callSelf -s "${destStackName}" shell 1 sh -c 'cd /db && rm -f * && cat /tmp/db.tar.gz | gzip -dc | tar -xf - && ( pkill -9 wavelet || true )' || retval='1'
	fi

	if [ "${retval}" = '0' ]; then
		callSelf -s "${destStackName}" update
	fi

	rm -f "${tmpDBFile}"

	return "${retval}"
}

# CLI function to copy files to/from a node in the current stack.  It is
# a wrapper around "docker cp".
function copyFiles() {
	local arg args
	local nodeID taskID containerID

	if [ "$#" = '0' ]; then
		echo "Usage: manage-stack [-s <stackName>] cp <src>... <dest>" >&2

		return 1
	fi

	args=()
	for arg in "$@"; do
		case "${arg}" in *:*)
			nodeID="$(echo "${arg}" | cut -f 1 -d :)"
			arg="$(echo "${arg}" | cut -f 2- -d :)"
			taskID="$(taskIDFromNodeID "${nodeID}")" || return 1
			containerID="$(containerIDFromTaskID "${taskID}")" || return 1
			arg="${containerID}:${arg}"
			;;
		esac

		args+=("${arg}")
	done

	if [ -n "${taskID}" ]; then
		setDockerMachineForTaskID "${taskID}"
	fi

	docker cp "${args[@]}"
}

# Internal function to run a command on all instances of a node for
# a given Docker service for the current stack.
function runOnService() {
	local service args
	local taskIDs

	service="${stackName}_$1"

	shift
	args=("$@")

	taskIDs=( $(docker service ps --filter "desired-state=Running" -q "${service}" ) )

	(
		for taskID in "${taskIDs[@]}"; do
			(
				containerID="$(containerIDFromTaskID "${taskID}")" || return 1
				setDockerMachineForTaskID "${taskID}"

				docker exec "${containerID}" "${args[@]}"
			) &
		done

		wait
	)

}

# Save the startup environment so we can reset to it, needed for some internal functions
startupEnvironment="$(export)"

# To make operating easier, change directories to the directory this script is in
cd "$(dirname "${BASH_SOURCE[0]}")" || exit 1

# Process optional arguments
setStackName=''
while getopts 's:' arg; do
	case "${arg}" in
		s)
			setStackName="${OPTARG}"
			;;
		':'|'?')
			usage >&2
			exit 1
			;;
	esac
done
shift $[${OPTIND} - 1]

action="$1"
shift

# Load configuration files for the current stack
configDir="./config"
globalEnvFile="${configDir}/default"
if [ -f "${globalEnvFile}" ]; then
	. "${globalEnvFile}"
fi

# Use the user-specified (on CLI) stack name over all config provided ones
if [ -n "${setStackName}" ]; then
	stackName="${setStackName}"
fi

# Compute the swarm name if none is provided
if [ -n "${stackName}" ]; then
	if [ -z "${swarmName}" ]; then
		swarmName="$(echo "${stackName}" | sed 's@-[^-]*$@@')"
	fi
else
	stackName="default-local"
fi
if [ -z "${swarmName}" ]; then
	swarmName='default'
fi

stackEnvFile="${configDir}/stacks/${stackName}"
if [ -f "${stackEnvFile}" ]; then
	. "${stackEnvFile}"
fi

swarmEnvFile="${configDir}/swarms/${swarmName}"
if [ -f "${swarmEnvFile}" ]; then
	. "${swarmEnvFile}"
fi

# If using a remote swarm, pull the configuration from the remote swarm
if [ -n "${DOCKER_MACHINE_NAME}" ]; then
	eval "$(docker-machine ssh "${DOCKER_MACHINE_NAME}" "cat '/etc/wavelet-stack/${stackName}' 2>/dev/null; exit 0")" || (
		echo "Unable to login to docker machine host" >&2
		exit 1
	) || exit 1
fi
export REGISTRY WAVELET_BENCHMARK_NODES WAVELET_GENESIS WAVELET_KEYS WAVELET_NODES WAVELET_RICH_WALLETS
export WAVELET_SNOWBALL_K WAVELET_SNOWBALL_BETA WAVELET_MEMORY_MAX WAVELET_NO_RPC WAVELET_TAG
export WAVELET_API_HOST WAVELET_API_ACME_ACCOUNT_KEY
export WAVELET_API_PORT WAVELET_RPC_PORT
export WAVELET_BACKUP_DB

# Map the CLI commands to their functions
case "${action}" in
	stop)
		stop
		exit "$?"
		;;
	start|update)
		start
		exit "$?"
		;;
	restart|restart-wavelet)
		runOnService wavelet pkill -9 -x /wavelet
		;;
	debug-wavelet)
		debugWavelet "$@"
		exit "$?"
		;;
	reset)
		stop || exit "$?"
		if [ "$1" = '--hard' ]; then
			cleanVolumes --force || exit "$?"
		fi
		start
		exit "$?"
		;;
	status|'')
		status "$@"
		exit "$?"
		;;
	attach|shell|logs|benchmark|nobenchmark|cleanVolumes)
		"${action}" "$@"
		exit "$?"
		;;
	cp)
		copyFiles "$@"
		exit "$?"
		;;
	config)
		dumpConfig
		exit 0
		;;
	edit-config)
		editConfig "$@"
		exit "$?"
		;;
	dump-db)
		dumpDB "$@"
		exit "$?"
		;;
	duplicate-stack)
		duplicateStack "$@"
		exit "$?"
		;;
	help)
		usage
		exit 0
		;;
	*)
		usage >&2
		exit 1
		;;
esac
