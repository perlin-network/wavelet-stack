#! /bin/bash

syncURL="http://sync:2379/v2/keys"
peersURL="${syncURL}/peers"
mappingURL="${syncURL}/mapping"
peerID="${WAVELET_NODE_ID}"

# Generate a random API secret to use to authenticate to
# Wavelet's HTTP API to make control requests
WAVELET_API_SECRET="$(dd if=/dev/urandom bs=32 count=1 2>/dev/null | sha256sum | cut -c 1-64)"
export WAVELET_API_SECRET

# Get the private and public key for a given node ID.  This will either pull
# from the built-in default keys (in /opt/perlin/etc/wallets) or from the
# CSV keys from the WAVELET_KEYS variable.
function getKey() {
	local id keys

	id="$1"

	if [ -z "${id}" ]; then
		id=$["${WAVELET_NODE_ID}" - 1]
	fi

	keys="$(echo "${WAVELET_KEYS}" | cut -f $["${id}" + 1] -d ,)"
	if [ -z "${keys}" ]; then
		keys="$(awk -v id="${id}" '($1 == id) { print $2, $3; exit }' </opt/perlin/etc/wallets)"
	fi

	echo "${keys}"
}

# Get the private key for a specified node ID
function getPrivateKey() {
	getKey "$@" | awk '{ print $1 }'
}

# Get the public key for a specified node ID
function getPublicKey() {
	getKey "$@" | awk '{ print $2 }'
}

# Get the local, internal, IP for the current instance
function getLocalIP() {
	getent hosts "$(uname -n)" | awk '{ print $1 }'
}

# Register ourselves with etcd on the "sync" node, include our local IP
# and the port specified and a 30s TTL
function registerPeer() {
	local ip port

	ip="$(getLocalIP)"
	port="$1"

	curl -SsL "${peersURL}/${peerID}" \
		-X PUT \
		--data value="${ip}:${port}" \
		--data ttl=30 >/dev/null 2>/dev/null
}

# Daemon function to maintain peer registration for our current node
# every 10s, using the port specified.
function maintainPeerRegistry() {
	local port
	port="$1"

	(
		while true; do
			registerPeer "${port}"
			sleep 10
		done

	) &
}

# Determine the CIDR for the current service.  This is used to
# determine which Wavelet peers are nodes that are in the stack
# and which ones are external peers.
function serviceCIDR() {
	local serviceName serviceIP serviceInterface serviceCIDR

	if [ -n "${cacheServiceCIDR}" ]; then
		echo "${cacheServiceCIDR}"

		return 0
	fi

	serviceName='sync'
	serviceIP="$(getent hosts "${serviceName}" | awk '{ print $1; exit }')"
	serviceInterface="$(ip -o route get "${serviceIP}" |  sed 's@^.* dev  *@@;s@ .*$@@')"
	serviceCIDR="$(ip -o addr show dev "${serviceInterface}" | sed 's@^.* inet  *@@;s@ .*$@@')"
	cacheServiceCIDR="${serviceCIDR}"

	echo "${cacheServiceCIDR}"

	return 0
}

# Function to determine if a given peer is an internal peer that
# is part of this stack or an external peer
function isSyncPeer() {
	local peer
	local servicePrefix serviceNetwork peerNetwork
	local externalIP

	peer="$1"

	if [ "${WAVELET_NO_RPC}" = 'true' ]; then
		# Verify the IP is an in the same range as the local nodes IP
		servicePrefix="$(ipcalc -p "$(serviceCIDR)" | cut -f 2 -d =)"
		serviceNetwork="$(ipcalc -n "$(serviceCIDR)" | cut -f 2 -d =)"
		peerNetwork="$(ipcalc -n "${peer}/${servicePrefix}" | cut -f 2 -d =)"

		if [ "${peerNetwork}" = "${serviceNetwork}" ]; then
			return 0
		fi
	else
		externalIP="$(getExternalIP | cut -f 1 -d :)"
		if [ "${peer}" = "${externalIP}" ]; then
			return 0
		fi
	fi

	return 1
}

# Ask the running wavelet instance for its peers and return them,
# optionally not filtering out external peers.
function getNodePeers() {
	local peers filteredPeers
	local peer
	local filter

	filter='true'
	if [ "$1" = '--nofilter' ]; then
		filter='false'
	fi

	peers=( $(curl -sSL http://localhost:9000/ledger 2>/dev/null | jq -crM '.peers[].address' 2>/dev/null | sort -u) )
	if [ "${peers}" = 'null' ]; then
		peers=''
	fi

	# Filter out all peers that are external to the cluster
	if [ "${WAVELET_NO_RPC}" != 'true' ]; then
		cacheExternalMappingData

		# Compute the serviceCIDR and cache it, for future calls
		unset cacheServiceCIDR
		serviceCIDR >/dev/null 2>/dev/null
	fi

	filteredPeers=()
	for peer in "${peers[@]}"; do
		if [ "${filter}" = 'true' ]; then
			if ! isSyncPeer "$(echo "${peer}" | cut -f 1 -d :)"; then
				#DEBUG#echo "  Skipping ${peer} (external; not in same subnet as $cacheServiceCIDR)" >&2
				continue
			fi
		fi
		filteredPeers+=("${peer}")
	done

	echo "${filteredPeers[*]}"

	return 0
}

# Get a list of other Wavelet peers running within the current stack
# which we should connect to in order to ensure that we have
# a well-connected Wavelnet network
function getSyncPeers() {
	local peerIDs
	local peer

	if [ "${WAVELET_NO_RPC}" = 'true' ]; then
		curl -SsL "${peersURL}" 2>/dev/null | \
			jq -crM '.node.nodes[] | select(.key | endswith("/peers/'"${peerID}"'") | not) | .value' 2>/dev/null | \
			sort -u | \
			grep -v '^null$'
	else
		peerIDs=( $(curl -sSL "${peersURL}" 2>/dev/null | jq -crM '.node.nodes[].key' | sed 's@^.*/@@') )
		for peer in "${peerIDs[@]}"; do
			if [ "${peer}" = "${peerID}" ]; then
				continue
			fi

			getExternalMappingData "${peer}" | cut -f 1-2 -d / | sed 's@/@:@g'
		done | sort -u
	fi
}

# Internal function to determine what the highest currently registered node ID among
# any active peers
function getMaxSyncPeerID() {
	curl -sSL "${peersURL}" | jq -crM '.node.nodes[].key' | sed 's@/peers/@@' | sort -n | tail -n 1

}

# Get the peer IP and port for a given node ID and type (api or rpc)
function getSyncPeer() {
	local id portType
	local peerIP

	id="$1"
	portType="$2"

	if [ -z "${portType}" ]; then
		portType='api'
	fi

	peerIP="$(curl -sSL "${peersURL}/${id}" 2>/dev/null | jq -crM .node.value)"

	case "${portType}" in
		rpc)
			;;
		api)
			peerIP="$(echo "${peerIP}" | cut -f 1 -d :):9000"
			;;
		*)
			echo "Invalid port type: ${portType}" >&2
			return 1
			;;
	esac

	echo "${peerIP}"

	return 0
}

# Cache mapping of Docker external ports to service internal ports so that
# they do not need to be looked up individually.  This mapping indicates
# what port Docker is listening on on the host and which port it is
# mapped to on the load balancer, which will then direct traffic to
# an internal Wavelet instance if so configured.
# If the cache already exists it will be updated.  If there is an
# error getting the mapping (e.g., because the mapping has not
# yet been pushed into the sync instance, or the sync instance
# is not running) then this function will wait until that is done.
function cacheExternalMappingData() {
	local data
	while true; do
		data="$(curl -sSL "${mappingURL}" 2>/dev/null | jq -crM '.node')"
		if [ "${data}" = 'null' ]; then
			data=''
		fi

		if [ -n "${data}" ]; then
			externalMappingDataCache="${data}"
			break
		fi

		sleep 0.5
	done
}

# Clean up caching of external ports, to ensure that fresh data is used
function uncacheExternalMappingData() {
	unset externalMappingDataCache
}

# Get the internal port for a given node ID
function getExternalMappingData() {
	local peer
	local data

	peer="$1"
	if [ -z "${peer}" ]; then
		peer="${peerID}"
	fi

	cacheExternalMappingData

	data="$(echo "${externalMappingDataCache}" | jq -crM '.nodes[] | select (.key == "/mapping/'"${peer}"'") | .value')"

	echo "${data}"

	return 0
}

# Get the port that Wavelet should listen on for incoming RPC connections.
# This will either be port 3000+node ID if no external RPC is enabled, or
# the port that Docker is listening on externally (because Wavelet needs
# to identify that port to advertise to other peers).
function getExternalPort() {
	local port

	if [ "${WAVELET_NO_RPC}" = 'true' ]; then
		port=$[3000 + $peerID - 1]
	else
		cacheExternalMappingData

		port="$(getExternalMappingData | cut -f 2 -d / | sort -n | head -n 1)"
	fi

	if [ -z "${port}" ]; then
		return 1
	fi

	echo "${port}"
}

# Get the IP address that Wavelet should advertise to other Wavelet instances
# that it should be contacted at.  If external RPC is used, this will be the
# cluster External IP.  If external RPC is not used, this will be the instance's
# local IP.
function getExternalIP() {
	local addr

	if [ "${WAVELET_NO_RPC}" = 'true' ]; then
		addr="$(getLocalIP)"
	else
		cacheExternalMappingData

		addr="$(getExternalMappingData | cut -f 1 -d /)"
	fi

	if [ -z "${addr}" ]; then
		return 1
	fi

	echo "${addr}"
}

# Periodically maintain database backups of the Wavelet database
function waveletDBBackup() {
	(
		backupDir='/data/backups'
		backupFile="${backupDir}/backup-$(date +%Y-%m-%d-%H-%M.tar.gz)"

		set -e

		mkdir -p "${backupDir}"
		cd /db

		if [ "$(echo *)" = '*' ]; then
			return
		fi

		tmpdir=''
		for try in {1..10} __fail__; do
			if [ -n "${tmpdir}" ]; then
				rm -rf "${tmpdir}"
			fi

			if [ "${try}" = '__fail__' ]; then
				exit 1
			fi

			tmpdir="$(mktemp -d)"

			(
				before="$(sha1sum * | sha1sum)"
				cp * "${tmpdir}/"
				after="$(sha1sum * | sha1sum)"

				if [ "${before}" = "${after}" ]; then
					exit 0
				else
					exit 1
				fi
			) && break
		done

		cd "${tmpdir}"

		tar -cf - * | gzip -9c > "${backupFile}"

		cd /

		rm -rf "${tmpdir}"

		cd "${backupDir}"
		find . -name 'backup-*.tar.gz' -mtime +2 -delete
	)
}

# Use the Wavelet HTTP API to request that it add (connect to) or
# remove (disconnect from) a peer we have discovered.
function addOrRemoveWaveletPeer() {
	local mode peer
	local curlArgs
	local output error msg

	mode="$1"
	peer="$2"

	curlArgs=(
		-H "Authorization: Bearer ${WAVELET_API_SECRET}"
		-d "{\"address\": \"${peer}\"}"
		"http://localhost:9000/node/${mode}"
	)

	output="$(curl -sSL "${curlArgs[@]}")"
	error="$(jq -crM .error <<<"${output}" 2>/dev/null)"
	msg="$(jq -crM .msg <<<"${output}" 2>/devnull)"

	if [ "${error}" = 'null' ]; then
		error=''
	fi

	if [ "${msg}" = 'null' ]; then
		msg=''
	fi

	if [ -z "${error}" -a -n "${msg}" ]; then
		return 0
	fi

	if [ -z "${msg}" -a -z "${error}" ]; then
		msg="${output}"
	fi

	if [ -z "${error}" ]; then
		error="${msg}"
	fi

	echo "Failed to ${mode} peer ${peer}: ${error}" >&2

	return 1
}

# Wrapper function to add a peer to the current Wavelet instance
function addWaveletPeer() {
	addOrRemoveWaveletPeer connect "$@"
}

# Wrapper function to remove a peer from the current Wavelet instance
function removeWaveletPeer() {
	addOrRemoveWaveletPeer disconnect "$@"
}

# Setup environment variables for running Wavelet and run the Wavelet
# instance this node provides.
function runWavelet() {
	local port
	local argNextArg
	local needPort
	local waveletAddArgs
	local startTime stopTime failCount

	# Migrate from the old storage schema of directly on the data
	# volume to in a separate sub-directory
	if [ ! -d /data/db ] ; then
		mkdir /data/db || return 1

		if [ -e /data/LOG -o -e /data/CURRENT ]; then
			(
				set -e
				cd /data
				mv * db

				if [ -d .certs ]; then
					mv .certs /data/certs
				fi

				if [ -d .backups ]; then
					mv .backups /data/backups
				fi
			) || exit 1
		fi
	fi

	ln -s /data/db /db

	port="$(getExternalPort)"
	nextArg=''
	needPort='true'
	for arg in "$@"; do
		if [ -n "${nextArg}" ]; then
			eval "${nextArg}"'=$arg'
			nextArg=''
		fi
		case "${arg}" in
			--port)
				nextArg='port'
				needPort='false'
				;;
		esac
	done

	if [ "${needPort}" = 'true' ]; then
		set -- "$@" --port "${port}"
	fi

	# Manage cert cache directory if the API host
	# is specified, this is needed to keep
	# the Let's Encrypt generated certificate
	# across upgrades, preventing API rate-limits
	# from being reached
	WAVELET_CERTS_CACHE_DIR=''
	if [ -n "${WAVELET_API_HOST}" ]; then
		WAVELET_CERTS_CACHE_DIR='/data/certs'
		mkdir -p "${WAVELET_CERTS_CACHE_DIR}"
		chmod 700 "${WAVELET_CERTS_CACHE_DIR}"
	fi
	export WAVELET_CERTS_CACHE_DIR

	# If the ACME API account key is provided
	# write it to disk where Wavelet is looking for it
	# this ensures that the Let's Encrypt certificates
	# for a stack's domain can be reliably renewed
	if [ -n "${WAVELET_API_ACME_ACCOUNT_KEY}" ]; then
		if [ -n "${WAVELET_CERTS_CACHE_DIR}" ]; then
			mkdir -p "${WAVELET_CERTS_CACHE_DIR}"
			echo "${WAVELET_API_ACME_ACCOUNT_KEY}" > "${WAVELET_CERTS_CACHE_DIR}/acme_account+key"
		fi
	fi

	# Start periodic process which registers our node with
	# etcd on the "sync" node so that every other Wavelet
	# node can find us to peer with us.
	maintainPeerRegistry "${port}"

	# If no vaild memory max value is provided unset the variable
	if [ -z "${WAVELET_MEMORY_MAX}" ] || [ "${WAVELET_MEMORY_MAX}" = '0' ]; then
		unset WAVELET_MEMORY_MAX
	fi

	# If no wallet was specified, look up the appropriate private key
	if [ -z "${WAVELET_WALLET}" ]; then
		WAVELET_WALLET="$(getPrivateKey)"
	fi

	# If no genesis block was provided as part of the stack, generate
	# an appropriate genesis block with the first N (where N is specified
	# in the variable WAVELET_RICH_WALLETS) accounts are "rich".
	if [ -z "${WAVELET_GENESIS}" ]; then
		for ((idx = 0; idx < ${WAVELET_RICH_WALLETS}; idx++)) {
			WAVELET_GENESIS="${WAVELET_GENESIS},"'"'"$(getPublicKey "${idx}")"'": {"balance": 10000000000000000000, "rewards": 5000000}'
		}
		WAVELET_GENESIS="{${WAVELET_GENESIS:1}}"
	fi
	export WAVELET_WALLET WAVELET_GENESIS

	# Disable the auto-updater for our internal nodes
	WAVELET_UPDATE_URL=''
	export WAVELET_UPDATE_URL

	# For debugging, write out the relevant Wavelet configuration environment
	# variables to disk.
	set | grep '^WAVELET' > /tmp/environment.txt

	# Determine if the Wavelet instance has the connect/disconnect API
	# for adding peers -- if so we can operate differently.
	haveConnectAPI='false'
	if /wavelet --help 2>/dev/null | grep 'WAVELET_API_SECRET' >/dev/null; then
		haveConnectAPI='true'
	fi

	# Create a new periodic routine which adds and removes peers
	# as they come/go from the registry on etcd on the "sync" node
	# This will use either the HTTP API for connect/disconnect or
	# killing Wavelet, which will cause it to use the new peers
	# on the command-line.
	while true; do
		sleep $[10 + ($RANDOM % 10)]

		if [ -z "${removeErrors}" ]; then
			removeErrors='0'
			addErrors='0'

			if [ "${haveConnectAPI}" = 'true' ]; then
				addErrorThreshold='1000'
				removeErrorThreshold='100'
			else
				addErrorThreshold='1'
				removeErrorThreshold='10'
			fi
		fi

		oldPeers=( $(getNodePeers) )
		curPeers=( $(getNodePeers --nofilter) )
		newPeers=( $(getSyncPeers) )

		if [ "${newPeers[*]}" != "${oldPeers[*]}" ]; then
			#DEBUG#echo "PEERS DIFFER:" >&2
			#DEBUG#echo "  OLD: ${oldPeers[*]}" >&2
			#DEBUG#echo "  NEW: ${newPeers[*]}" >&2

			for oldPeer in "${oldPeers[@]}"; do
				peerStillValid='false'
				for newPeer in "${newPeers[@]}"; do
					if [ "${oldPeer}" = "${newPeer}" ]; then
						peerStillValid='true'
						break
					fi
				done

				if [ "${peerStillValid}" = 'false' ]; then
					echo "  Removing: ${oldPeer}" >&2
					if removeWaveletPeer "${oldPeer}"; then
						removeErrors='0'
					else
						removeErrors=$[$removeErrors + 1]
					fi
				fi
			done

			if [ "${#curPeers[@]}" -lt $[${WAVELET_SNOWBALL_K} + 1] ]; then
				for newPeer in "${newPeers[@]}"; do
					peerAlreadyPresent='false'
					for oldPeer in "${oldPeers[@]}"; do
						if [ "${oldPeer}" = "${newPeer}" ]; then
							peerAlreadyPresent='true'
							break
						fi
					done

					if [ "${peerAlreadyPresent}" = 'false' ]; then
						echo "  Adding: ${newPeer}" >&2
						if addWaveletPeer "${newPeer}"; then
							addErrors='0'
						else
							addErrors=$[$addErrors + 1]
						fi
					fi
				done
			fi

			# If there is a continious stream of errors coming from Wavelet
			# then kill the process and let it sort itself out
			if [ "${removeErrors}" -gt 0 -o "${addErrors}" -gt 0 ]; then
				echo "  Error Counts: Remove: ${removeErrors}/${removeErrorThreshold}; Add: ${addErrors}/${addErrorThreshold}" >&2
			fi
			if [ "${removeErrors}" -gt "${removeErrorThreshold}" -o "${addErrors}" -gt "${addErrorThreshold}" ]; then
				addErrors='0'
				removeErrors='0'
				pkill -9 -x /wavelet
			fi
		fi
	done &

	# If requested, backup the Wavelet DB every 30 minutes.  This will
	# also remove older backups.
	if [ "${WAVELET_BACKUP_DB}" = 'true' ]; then
		while true; do
			waveletDBBackup
			sleep $[60 * 30]
		done &
	fi

	# Run the wavelet process in a loop so that exiting just
	# causes it to reload, unless a special marker file
	# exists
	retval='1'
	waveletAddArgs=()
	while true; do
		if [ -f /tmp/wavelet.exit ]; then
			break
		fi

		# If we lack the HTTP API for connect/disconnect,
		# specify known peers as command line arguments
		if [ "${haveConnectAPI}" = 'false' ]; then
			waveletAddArgs=( $(getSyncPeers) )
		fi

		startTime="$(date +%s)"

		/wavelet --host "$(getExternalIP)" "$@" "${waveletAddArgs[@]}"
		retval="$?"

		stopTime="$(date +%s)"

		# If the daemon exited more quickly than 3 seconds assume it is
		# a failure and increment repeated failure count.
		if [ $[${stopTime} - ${startTime}] -lt 3 ]; then
			failCount=$[${failCount} + 1]
		else
			failCount='0'
		fi

		# If there are too many failures in a row assume the database is
		# broken, make a backup copy of the database and delete the DB.
		if [ "${failCount}" -gt 10 ]; then
			(
				set -e
				cd /data/db
				mkdir -p "/data/broken/date-${stopTime}"
				mv * "/data/broken/date-${stopTime}/"
				rm -f *
			)
			failCount='0'
		fi

		sleep 0.1
	done
	exit "${retval}"
}

# Run the benchmark tool against a peer, ensure that each instance of the benchmark
# will connect to a different Wavelet instance (as long as there are enough Wavelet
# instances in this stack)
function runBenchmark() {
	local otherPeerID otherPeerIP

	otherPeerID=$[("${peerID}" % $(getMaxSyncPeerID)) + 1]
	otherPeerIP="$(getSyncPeer "${otherPeerID}")"

	echo "Benchmarking against node ${otherPeerID} (${otherPeerIP})"

	exec /benchmark remote --host "${otherPeerIP}" --wallet "$(getPrivateKey)"

	exit 1
}

# Start the appropriate tool
## Default to bash if no tool is specified
if [ "$#" = '0' ]; then
	set -- bash
fi

mode="$1"
shift

case "${mode}" in
	wavelet)
		runWavelet "$@"
		;;
	benchmark)
		runBenchmark "$@"
		;;
	*)
		# Any other tool, run it
		exec "${mode}" "$@"
		;;
esac
